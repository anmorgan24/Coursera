{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80bc89a4",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50219ba9",
   "metadata": {},
   "source": [
    "- You can look at Production Machine Learning as both Machine Learning itself, and the knowledge and skils required in modern Software Development\n",
    "- If you're working on a Machine Learning team in industry, you really need expertise in both Machine Learning and Software to be successful. This is because your team will not just be producing a single result, you'll be developing a product or service that will operate continuously and may be a mission critical part of your company's work\n",
    "- Oftentimes the most challenging aspects of building machine learning systems turn out to be the things you least expected, like deployment. It's all very well being able to build a model, but getting that into people's hands and seeing how they use it can be very eye-opening\n",
    "\n",
    "<img src='img/2.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "\n",
    "### The Machine Learning Project Lifecycle\n",
    "- **Edge device:** A device that is living inside the factory that is manufacturing these smart phones and that edge device will have a piece of inspection software\n",
    "- **Inspection software:** Piece of software whose job it is to take a picture of the phone to see if there is a scratch, and then make a decision on whether this phone is acceptable or not.\n",
    "- The above is called **Automated Visual Defect Inspection**\n",
    "\n",
    "<img src='img/3.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd785b8",
   "metadata": {},
   "source": [
    "- Take X images of phones and map them to Y predictions (defective or not?)\n",
    "- The prediction server is sometimes in the cloud, and sometimes at the edge device as well (in manufacturing, edge deployment is common because you can't have your factory go down every time your internet access goes down)\n",
    "- **For many ML Projects, maybe only 5-10% (or less) of the code is actually ML model code.**\n",
    "- **POC** = Proof of concept\n",
    "- This is one of the reasons why, when you have a proof-of-concept model working, it can still be a lot of work to go to production deployment\n",
    "\n",
    "<img src='img/4.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3b3e6",
   "metadata": {},
   "source": [
    "- In this course we learn all of the \"other\" pieces of software needed for a valuable production deployment\n",
    "\n",
    "<img src='img/5.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "- The \"MLOps Amoeba:\"\n",
    "\n",
    "<img src='img/6.png' width=\"900\" height=\"450\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562cb6f6",
   "metadata": {},
   "source": [
    "## Steps of an ML Project\n",
    "\n",
    "<img src='img/1.png' width=\"900\" height=\"450\" align=\"center\"/>\n",
    "\n",
    "- Potential key metrics in an NLP project:\n",
    "    - Accuracy\n",
    "    - Latency\n",
    "    - Throughput\n",
    "\n",
    "#### Data Definition Questions:\n",
    "- Is the data labeled consistently?\n",
    "- For an audio clip: how much silence before/after each clip?\n",
    "- How to perform volume normalization?\n",
    "\n",
    "\n",
    "- A lot of progress in ML was driven by ML research working to improve performance on benchmarked datasets\n",
    "- What are some systemic frameworks to ensure you have high quality data in a live production environment?\n",
    "\n",
    "#### Three Key Inputs to Training an ML Model\n",
    "- Code (algorithm/model architecture)\n",
    "- Hyperparameters\n",
    "- Data\n",
    "\n",
    "\n",
    "- In a lot of **research/academia**, the data is held fixed, while the code and hyperparameters may vary in order to try to get good performance\n",
    "- In contrast, on a lot of **product teams** (if your main goal is to build and deploy a working, valuable machine learning system, it can be more effective to hold the code fixed, and to instead focus on optimizing the hyperparameters and the data.\n",
    "\n",
    "\n",
    "An ML System = Code + Data (+ Hyperparameters)\n",
    "- Rather than taking a model-centric view of trying to optimize the code to your fixed data set, for many problems you can use an open source implementation of something and instead just focus on optimizing your data\n",
    "- Part of the trick is you don't want to just feel like you need to collect more data all time, but instead of just collecting more and more data (which is helpful, but expensive and time consuming) is if error analysis can help you be more targeted in exactly what data to collect, that can help you be much more efficient in building an accurate model.\n",
    "\n",
    "<img src='img/7.png' width=\"900\" height=\"450\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56a4f0",
   "metadata": {},
   "source": [
    "- Even after an ML system like the one outlined above is up and running, however, **you still need to monitor and maintain the system.**\n",
    "- **One of the key challenges when it comes to deployment:**\n",
    "    - Concept drift\n",
    "    - Data drift\n",
    "    \n",
    "### Course Outline\n",
    "- Deployment\n",
    "- Modeling\n",
    "- Data\n",
    "\n",
    "\n",
    "- MLOps (Machine Learning Operations) is an emerging discipline, and comprises a set of tools and principles to support progress through the ML project lifecycle.\n",
    "- A key idea in MLOps is that there are systematic ways to think about scoping, data, modeling, and deployment, and also software tools to support best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85863f77",
   "metadata": {},
   "source": [
    "### Deployment: Key Challenges \n",
    "- Two major categories of challenges in deploying an ML model\n",
    "    - 1) ML or statistical issues\n",
    "    - 2) Software Engineering Issues\n",
    "    \n",
    "#### Concept Drift and Data Drift\n",
    "- Loosely: What if your data changes after your system has already been deployed\n",
    "- Data shift types:\n",
    "    - Gradual change\n",
    "    - Sudden change/shock\n",
    "- The terminology to describe different data changes is not used completely consistently \n",
    "- **Data Drift:** when the input distrubtion of X changes (in X $\\Rightarrow$ Y)\n",
    "- **Concept Drift:** When the desired mapping from X $\\Rightarrow$ Y changes\n",
    "\n",
    "#### Software Engineering Issues\n",
    "- A lot of speech systems in cars run on edge devices, and even some speech recognition systems on mobile devices run on a browser or edge device.\n",
    "- Make sure you have similar CPU/GPU/memory capacity in deployment environment as you do in the testing environment \n",
    "- **QPS = Queries Per Second**\n",
    "- In speech recognition applications, it's not unusual to aim to get a response back to the user within half a second, or 500 ms.\n",
    "    - Of this 500ms budget, you may be able to allocate 300ms to your speech recognition task; this gives a latency requirement for your system\n",
    "    - **Throughput** refers to \"how many queries per second do you need to handle, given your compute resources?\" (maybe given a certain number of cloud servers)\n",
    "- **Logging:** When building your system, it may be useful to log as much of the data for analysis and review as well as to provide more data for retraining your learning algorithm in the future\n",
    "- **Security and Privacy:** For different applications the required levels of security and privacy can be very different.\n",
    "\n",
    "<img src='img/7.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "-**Deploying a system requires two broad sets of tasks:**\n",
    "    - Writing the **software** to enable you to deploy the system into production.\n",
    "    - What you need to do to **monitor the system performance and continue to maintain it**, especially in the case of:\n",
    "        - **Concept Drift**\n",
    "        - **Data Drift**\n",
    "- One of the things you see when building machine learning systems is that the practices for the very first deployment will be quite different compared to when you are updating or maintaining a system that has already previously been deployed\n",
    "- There are some ML Engineers that view deploying the ML model as \"getting to the finish line,\" but unfortunately, making it to the first deployment means you're more like (about) halfway there.\n",
    "    - Even after you've deployed there's a lot of work to feed the data back and maybe to update the model to keep on maintaining the model even in the face of changes to the data.\n",
    "    \n",
    "<img src='img/8.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bfeddd",
   "metadata": {},
   "source": [
    "### Deployment patterns\n",
    "- When deploying systems, there are a number of commun use cases, as well as different patterns (as to how you would deploy, depending on your use case).\n",
    "\n",
    "#### Common Deployment Cases \n",
    "- **New product/capability**\n",
    "    - for example: a speech recognition service that you have not offered before\n",
    "    - in this case, a common design pattern is to start with a small amount of traffic and then gradually ramp it up\n",
    "- **Automate/assist with manual task**\n",
    "    - Another common use case: if there is something that's already being done by a person, that we would now like to use a machine learning algorithm to either automate or assist with that learning task\n",
    "    - For example: if you had people in a factory inspecting smartphones for scratches, but now you would like to use a learning algorithm to either assist or automate that task\n",
    "    - The fact that people were previously doing this gives you a few more options for how you deploy, and you see **[shadow mode deployment](https://christophergs.com/machine%20learning/2019/03/30/deploying-machine-learning-applications-in-shadow-mode/)** (aka \"Dark Launch,\" according to Google) take advantage of this.\n",
    "        - **Shadow Mode/Dark Launch:** a technique where production traffic and data is run through a newly deployed version of a service or machine learning model, without that service or model actually returning the response or prediction to customers/other systems.\n",
    "        - Instead, the old version of the service or model continues to serve respnses or predictions, and the new version's results are merely captured and stored for analysis.\n",
    "        - Often, shadow mode is utilized when shifting from a fully manual task, to a fully- or partially-automated task.\n",
    "- **Replace previous ML system**\n",
    "    - If you've already been doing this task with a previous implementation of ML system but you now want to replace it with (hopefully) an even better one\n",
    "    \n",
    "\n",
    "#### Recurring Themes/Key Ideas:\n",
    "- Gradual ramp up with monitoring\n",
    "- Rollback\n",
    "\n",
    "<img src='img/9.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27f040",
   "metadata": {},
   "source": [
    "### Shadow Mode\n",
    "\n",
    "<img src='img/10.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Canary Deployment\n",
    "- When you are ready to start letting an ML algorithm start making decisions, a common deployment pattern is to use a **Canary Deployment**\n",
    "- In a canary deployment, you would roll out to a small fraction (say 5%, maybe even less) of traffic intitially and start letting the ML start making decisions\n",
    "- This way if the algorithm makes any mistakes, it will hopefully only affect a small fraction, giving you more of an opportunity to monitor the system and ramp up the percentage of traffic you get only gradually, and only when you have greater confidence in the performance\n",
    "\n",
    "<img src='img/11.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Blue green deployment\n",
    "- Have the router suddenly switch the traffic over from the old router to the new router\n",
    "- Typically in a blue/green deployment you switch over 100%, but of course you can also use a more gradual version\n",
    "\n",
    "<img src='img/12.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "- **As you may expect, whichever deployment pattern you use, quite a lot of software is needed to execute it.**\n",
    "- MLOps tools can help with implementing these deployment patterns (or you can implement yourself "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de444ee",
   "metadata": {},
   "source": [
    "### Degrees of automation\n",
    "- One of the most useful frameworks for thinking about how to deploy a system, is to think about deployment not as a 0-1 (deploy or not deploy), but instead to design a system thinking about what is the appropriate degree of automation\n",
    "- Many ML application deployments will start from the left of the image below, and gradually move to the right:\n",
    "\n",
    "<img src='img/13.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44902b",
   "metadata": {},
   "source": [
    "- In the above example, both \"AI assistance\" and \"Partial automation\" are examples of **human-in-the-loop.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75887c8",
   "metadata": {},
   "source": [
    "### Monitoring\n",
    "- The most common way to monitor an ML system is to use a dashboard\n",
    "- How to decide what to monitor in your dashboard?\n",
    "    - Brainstorm the things that could go wrong\n",
    "    - Brainstorm a few statistics/metrics that will detect the problem\n",
    "    - It is ok (and sometimes advisable) to use (\"too\") many metrics initially and gradually remove the ones you don't find useful\n",
    "    \n",
    "<img src='img/14.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "- Often you'll want to set thresholds for alarms \n",
    "- Okay to adapt both thresholds and metrics over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7832b4b",
   "metadata": {},
   "source": [
    "### Examples of metrics to track\n",
    "- 3 metrics to track: software metrics, input (x) metrics, output (y) metrics\n",
    "\n",
    "\n",
    "- **Software metrics:**\n",
    "    - Memory\n",
    "    - Compute\n",
    "    - Latency\n",
    "    - Throughput\n",
    "    - Server load\n",
    "- **Statistical/Performance metrics:**\n",
    "    - **Input metrics: metrics that measure if your input distribution `x` changes**\n",
    "        - Avg input length\n",
    "        - Avg input volume\n",
    "        - Number or percentage of missing values (structured data)\n",
    "        - Avg image brightness\n",
    "    - **Output metrics: metrics that measure if your output distribution `y` changes**\n",
    "        - \\# times return \"\" (null)\n",
    "        - \\# times user redoes search (imperfect but sometimes helpful signal)\n",
    "        - \\# times user switches to typing (after trying to use speech system)\n",
    "        - Click-through rate (CTR)\n",
    "        \n",
    "\n",
    "- Because input and output metrics are application specific, most MLOps tools will need to be configured specifically to track the input and output metrics for your application.\n",
    "- On the other hand, oftentimes software metrics will be built into the tools you use.\n",
    "\n",
    "#### Just as ML modeling is iterative, so is deployment\n",
    "- When you get your first deployment monitoring dashboards up and running, that's only the start of this iterative process\n",
    "- A running system allows you to get real user data or real traffic, and it is by seeing how your learning algorithm performs on real data/traffic that you can perform performance analysis\n",
    "- This, in turn, helps you to up update/improve your deployment and to keep on monitoring your system\n",
    "- It is an iterative process to find and choose the right set of metrics to monitor\n",
    "- When a model needs to be updated, you can either retrain it manually (more common) or automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc1c51",
   "metadata": {},
   "source": [
    "### Pipeline monitoring\n",
    "- Many AI systems are not just a single ML model running a prediction service, but instead involves a pipeline of multiple steps\n",
    "- So how do you build monitoring systems for machine learning pipelines?\n",
    "- When building monitoring systems for complex ML pipeline which can have ML components or non-ML-based components throughoutout the pipeline, it may be useful to brainstorm metrics to monitor that can detect changes in concept drift or data drift both at multiple stages of the pipeline \n",
    "\n",
    "#### Metrics to monitor\n",
    "- **Software metrics** (for individual components, as well as the whole pipeline)\n",
    "- **Input metrics** (for individual components, as well as the whole pipeline)\n",
    "- **Output metrics** (for individual components, as well as the whole pipeline)\n",
    "\n",
    "- How quickly do these metrics change? $\\leftarrow$ very application-dependent\n",
    "    - User data generally has slower drift (some exceptions: new trends, holidays, news, etc)\n",
    "    - Enterprise data (B2B applications) can shift quickly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1a620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e800d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930f431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d44b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8e13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74306b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41faaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122873f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67add743",
   "metadata": {},
   "source": [
    "<img src='img/x.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
