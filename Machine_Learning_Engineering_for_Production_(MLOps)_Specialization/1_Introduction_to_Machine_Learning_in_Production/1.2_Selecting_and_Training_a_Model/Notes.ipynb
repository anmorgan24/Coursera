{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016bf241",
   "metadata": {},
   "source": [
    "# Selecting and Training a Model\n",
    "- Some best practice for building a machine learning model that is worthy of a production deployment\n",
    "- Model-centric AI development vs Data-centric AI development\n",
    "\n",
    "### Key Challenges\n",
    "AI system = Code (algorithm/model) + Data\n",
    "- A lot of times it will be more efficient to spend more of your time improving the data because the data usually has to be much more customized to your problem \n",
    "- When building a model, there are three key milestones that most models should aspire to accomplish:\n",
    "    - 1. Doing well on training set (usually measured by average training error).\n",
    "    - 2. Doing well on dev/test sets.\n",
    "    - 3. Doing well on business metrics/project goals.\n",
    "    \n",
    "### Why low average error isn't good enough\n",
    "#### Performance on disproportionately important examples\n",
    "- Web search example:\n",
    "    - **Informational and transactional queries:**\n",
    "        - \"Apple pie,\" \"Wireless data plan,\" \"Latest movies,\" \"Diwali festival.\"\n",
    "        - For informational and transactional queries, a web search engine wants to return the most relevant results, but users are willing to forgive (maybe) ranking the best result as number 2 or 3\n",
    "    - **Navigational queries:**\n",
    "        - \"Stanford,\" \"Reddit,\" \"YouTube.\"\n",
    "        - Here the user has a very clear desire to go to a particular place\n",
    "        - When a user has a very clear navigational intent, they will tend to be very unforgiving if the websearch engine does anything other than return the exact result\n",
    "        - A web search engines that doesn't return the best results will very quickly lose the trust of its users.\n",
    "        - So, navigational queries in this context are disproportionately important set of examples\n",
    "- The problem is that average test set accuracy tends to weight all examples equally, whereas in many cases some scenarios are disproportionately important. \n",
    "\n",
    "#### Performance on key slices of the dataset\n",
    "- **Example: ML for loan approval**\n",
    "    - Make sure not to discriminate by ethnicity, gender, location, language, or other protected attributes\n",
    "    - **Even if a learning algorithm for loan approval achieves high average test set accuracy, it would not be acceptable for production deployment if it exhibits an unacceptable level of bias or discrimination.**\n",
    "- **Example: Product recommendations from retailers**\n",
    "    - Be careful to treat fairly all major user-, retailer-, and product- categories/groups.\n",
    "    \n",
    "#### Rare classes\n",
    "- Skewed data distributions\n",
    "- Accuracy in rare classes\n",
    "\n",
    "### Establish a baseline\n",
    "- HLP (Human-Level Performance) is often a good point of comparison or a baseline that helps you decide where to focus your efforts\n",
    "\n",
    "<img src='img/1.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Unstructured and structured data\n",
    "- It turns out the best practices for establishing a baseline are quite different depending on whether you are using unstructured or structured data. \n",
    "- Because humans are so good at interpreting **unstructured data**, using HLP as a comparison is often a good way of establishing a baseline\n",
    "- In contrast, because humans are not as good at looking at **structured (tabular) data** and making predictions, HLP is generally a less useful baseline.\n",
    "- In general, ML best practices are typically very different depending on whether you're working with structured or unstructured data.\n",
    "\n",
    "<img src='img/2.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32385348",
   "metadata": {},
   "source": [
    "#### Ways to establish a baseline\n",
    "- Human level performance (HLP) $\\rightarrow$ particularly for unstructured data problems. \n",
    "- Literature seach for state-of-the-art/open source (to see what others are able to accomplish).\n",
    "- Quick and dirty implementation \n",
    "- Performance of an older system (for example, if you already have a machine learning system running and are looking to replace it).\n",
    "\n",
    "**Baseline helps to indicate what might be possible. In some cases (such as HLP) it also gives a sense of what is irreducible error/Bayes' error.**\n",
    "\n",
    "#### Tips for getting started on modeling\n",
    "- Literature to see what's possible (courses, blogs, open-source projects).\n",
    "- Find open-source implementations if possible.\n",
    "- **A reasonable algorithm with good data will often outperform great a great algorithm with not so good data.**\n",
    "\n",
    "#### Deployment constraints when picking a model\n",
    "- Should you take into account deployment constraints (such as compute constraints) when picking a model?\n",
    "    - **Yes**, if baseline is already established and goal is to build and deploy.\n",
    "    - **No**, (or not necessarily), if purpose is to establish a baseline and determine waht is possible and might be worth pursuing.\n",
    "\n",
    "#### Sanity-check for code and algorithm\n",
    "- Try to overfit a small training dataset before training on a large one (especially if the output is a complex output).\n",
    "    - Example \\#1: Speech recognition\n",
    "    - Example \\#2: Image segmentation\n",
    "    - Example \\#3: Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f6687",
   "metadata": {},
   "source": [
    "## Error Analysis and Performance Auditing\n",
    "- Error analysis within a Jupyter notebook or Excel spreadsheet is common, but there are also emerging MLOps tools to make this process much more accurate, efficient, and in some cases, automated.\n",
    "\n",
    "<img src='img/3.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "- Error analysis is an iterative process\n",
    "\n",
    "<img src='img/4.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Useful metrics for each tag\n",
    "- What fraction of errors has that tag?\n",
    "- Of all the data with that tag, what fraction is misclassified?\n",
    "- What fraction of all the data has that tag?\n",
    "- How much room for improvement is there on data with that tag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11786906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a36d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a14609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a81aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1fe8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a6127eb",
   "metadata": {},
   "source": [
    "<img src='img/x.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
